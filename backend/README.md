# ğŸŒ¾ Agriculture Assistant - Backend

âš¡ The backend service for the Agriculture Assistant, handling LLM integration, business logic, and coordinating between components.

## âœ¨ Features

- ğŸ¤– LLM integration (Ollama: deepseek-r1, qwen2.5vl)
- ğŸ“ Prompt generation and management
- ğŸ” RAG system coordination
- ğŸ”Œ MCP (Model-Computer-Program) tool integration
- ğŸ”Š Audio processing for speech output

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.9+
- **LLM Integration:** Ollama client
- **Database:** Postgres (via MCP)
- **API:** FastAPI

## ğŸš€ Getting Started

### ğŸ“¥ Installation

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### ğŸ”„ Running the Service

```bash
# Start the backend server
uvicorn main:app --reload --port 8000
```

## ğŸ§© Key Components

- ğŸ¯ `main.py`: Entry point with core prompt generation logic
- ğŸ” `rag/rag.py`: RAG system integration and document retrieval
- ğŸ“ `utils/promptsArchive.py`: Prompt templates for different use cases
- ğŸ¤– `utils/models.py`: LLM interaction utilities
- ğŸ”Œ `utils/mcp.py`: Database interaction via MCP tools

## ğŸ§  LLM Integration

The backend communicates with Ollama to run models:

- ğŸŒ± **deepseek-r1:7b**: For general agricultural advice
- ğŸ–¼ï¸ **qwen2.5vl:7b**: For multimodal inputs (text + images)
- ğŸš€ **qwen3:32b**: For more complex analysis tasks

## ğŸ”Œ API Endpoints

- ğŸ” `/analyze`: Main endpoint for processing user queries
- ğŸ” RAG-related endpoints for document search and retrieval
- ğŸ’¾ MCP tool endpoints for database operations
